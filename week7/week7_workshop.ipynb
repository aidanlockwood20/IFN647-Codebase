{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abe4f0fc",
   "metadata": {},
   "source": [
    "# IFN647 Week 7 Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05127b9",
   "metadata": {},
   "source": [
    "## Task 2 \n",
    "Read a topic-doc-assignment file (e.g. relevance_judgements.txt, the benchmark) and a retrieved topic-doc-assignment file (e.g., binary_output.txt, the output of an IR model for query R105) and calculate the IR model's Recall, Precision and F-measure (F1).\n",
    "\n",
    "- Please download two topic-doc-assignment files (rel_data.zip) and save them as a folder (e.g. \"rel_data\"). Both files have the format of \n",
    "\n",
    "Topic | DocumentID | Relevance \n",
    "\n",
    "For the file \"relevance_judgements.txt\", Relevance (Relevance Judgement) = \"1\" indicates relevant and \"0\" means non-relevant. For the file \"binary_output.txt\", the relevance values are generated by the IR model. We can obtain a set of retrieved documents by selecting thev rows with Relevance (Relevance Values) = \"1\". \n",
    "\n",
    "- Define a function rel_setting(inputpath), which reads the two topic-doc-assignment files in the folder `inputpath` and returns a pair of dictionaries {documentID: Relevance_judgement, ...} and {document:Relevance_value, ...} for all documents in \"relevance_judgements.txt\" and \"binary_output.txt\", respectively\n",
    "- Define a main function to call function `rel_setting()`, calculate Recall, Precision and F-measure and display the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b58fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant libraries\n",
    "import os\n",
    "\n",
    "# Important variables\n",
    "curr_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8820a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    open_file = open(file_path, 'r')\n",
    "    lines = open_file.readlines()\n",
    "    open_file.close()\n",
    "    return lines\n",
    "\n",
    "def rel_setting(inputpath): \n",
    "    relevance_values = {}\n",
    "    judgement_values = {}\n",
    "\n",
    "    target_folder = os.path.join(curr_dir, inputpath)\n",
    "\n",
    "    folder_items = os.listdir(target_folder)\n",
    "    for file in folder_items:\n",
    "        full_file_path = os.path.join(target_folder, file)\n",
    "\n",
    "        # Skipping the ranked output file\n",
    "        if file != 'ranked_output.txt':\n",
    "            lines = open_file(full_file_path)\n",
    "        if file == 'relevance_judgments.txt':\n",
    "            for line in lines:\n",
    "                line = line.replace('\\n', '')\n",
    "                line = line.split(' ')\n",
    "                relevance_values[line[1]] = line[2]\n",
    "        if file == 'binary_output.txt': \n",
    "            for line in lines:\n",
    "                line = line.replace('\\n', '')\n",
    "                line = line.split(' ')\n",
    "                judgement_values[line[1]] = line[2]           \n",
    "\n",
    "    return relevance_values, judgement_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732c2db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of relevant documents: 16\n",
      "The nuumber of retrieved documents: 37\n",
      "The number of retrieved documents that are relevant: 14\n",
      "Recall = 0.875\n",
      "Precision = 0.3783783783783784\n",
      "F-measure = 0.5283018867924528\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Recall, Precision and F-measures \n",
    "def main_function_task2(inputpath):\n",
    "    relevance_results, judgement_results = rel_setting(inputpath)\n",
    "\n",
    "    relevant_docs = 0\n",
    "\n",
    "    for value in relevance_results.items():\n",
    "        if value[1] == '1':\n",
    "            relevant_docs += 1\n",
    "\n",
    "    judgement_relevant_docs = 0\n",
    "    for value in judgement_results.items():\n",
    "        if value[1] == '1':\n",
    "            judgement_relevant_docs += 1\n",
    "\n",
    "    print(f'The number of relevant documents: {relevant_docs}')\n",
    "    print(f'The nuumber of retrieved documents: {len(judgement_results)}')\n",
    "    print(f'The number of retrieved documents that are relevant: {judgement_relevant_docs}')\n",
    "\n",
    "    recall = judgement_relevant_docs / relevant_docs\n",
    "    print(f'Recall = {recall}')\n",
    "    precision = judgement_relevant_docs / len(judgement_results)\n",
    "    print(f'Precision = {precision}')\n",
    "    f_measure = (2 * precision * recall) / (precision + recall)\n",
    "    print(f'F-measure = {f_measure}')\n",
    "    return \n",
    "\n",
    "main_function_task2('rel_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e96bd23",
   "metadata": {},
   "source": [
    "## Task 3:\n",
    "Read the ranked output file (\"ranked_output.txt\", the ranked output of another IR model for query R105), and calculate the average precision \n",
    "\n",
    "- Please download the ranked output file and save it in the same folder you created for Task 2\n",
    "- Extend function rel_setting(inputpath) to return 3 dictionaries (two for task 2 and one for task 3). The dictionary for task 3 should have the format of {rankingNo: documentID, ...} and it only includes top-10 documents (ranked in descending order), where rankingNo = 1, 2, ..., 10.\n",
    "- Extend the main function to calculate Recall and Precision at the rank positions where a relevant document was retrieved, and then calculate the average precision and print out the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875ba4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_3_file = os.path.join(curr_dir, 'rel_data', 'ranked_output.txt')\n",
    "\n",
    "ranked_output_file = open_file(task_3_file)\n",
    "\n",
    "def rel_setting_task_3(inputpath): \n",
    "    relevance_values = {}\n",
    "    judgement_values = {}\n",
    "    sorted_ranking = {}\n",
    "    document_ranking = {}\n",
    "\n",
    "    target_folder = os.path.join(curr_dir, inputpath)\n",
    "\n",
    "    folder_items = os.listdir(target_folder)\n",
    "    for file in folder_items:\n",
    "        full_file_path = os.path.join(target_folder, file)\n",
    "        lines = open_file(full_file_path)\n",
    "        # Skipping the ranked output file\n",
    "        if file == 'ranked_output.txt':\n",
    "            for line in lines:\n",
    "                line = line.replace('\\n', '')\n",
    "                line = line.split(' ')\n",
    "\n",
    "                sorted_ranking[line[1]] = line[2]\n",
    "\n",
    "            # Sorting ther document ranking in descending order\n",
    "            sorted_ranking = dict(sorted(sorted_ranking.items(), key=lambda item: item[1], reverse=True)[:10])\n",
    "            i = 1\n",
    "            for item, value in sorted_ranking.items():\n",
    "                document_ranking[i] = item\n",
    "                i += 1\n",
    "        if file == 'relevance_judgments.txt':\n",
    "            for line in lines:\n",
    "                line = line.replace('\\n', '')\n",
    "                line = line.split(' ')\n",
    "                relevance_values[line[1]] = line[2]\n",
    "        if file == 'binary_output.txt': \n",
    "            for line in lines:\n",
    "                line = line.replace('\\n', '')\n",
    "                line = line.split(' ')\n",
    "                judgement_values[line[1]] = line[2]           \n",
    "\n",
    "    return relevance_values, judgement_values, document_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ecf9e7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2493': '1',\n",
       " '2494': '1',\n",
       " '3008': '1',\n",
       " '5004': '1',\n",
       " '5223': '0',\n",
       " '5225': '1',\n",
       " '5226': '1',\n",
       " '6635': '0',\n",
       " '7937': '0',\n",
       " '15744': '1',\n",
       " '17650': '0',\n",
       " '22961': '0',\n",
       " '25263': '0',\n",
       " '26711': '0',\n",
       " '27966': '0',\n",
       " '28198': '0',\n",
       " '31141': '0',\n",
       " '33961': '0',\n",
       " '38229': '0',\n",
       " '40239': '1',\n",
       " '40259': '1',\n",
       " '48148': '1',\n",
       " '48587': '0',\n",
       " '49633': '1',\n",
       " '50202': '0',\n",
       " '51493': '1',\n",
       " '52175': '0',\n",
       " '59813': '0',\n",
       " '62213': '0',\n",
       " '64966': '0',\n",
       " '65210': '0',\n",
       " '80118': '0',\n",
       " '80483': '0',\n",
       " '80484': '1',\n",
       " '80884': '1',\n",
       " '86042': '1',\n",
       " '86961': '1'}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance_results, judgement_results, document_ranking = rel_setting_task_3('rel_data')\n",
    "relevance_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12602c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function_task3(inputpath):\n",
    "    relevance_results, judgement_results, document_rankings = rel_setting_task_3(inputpath)\n",
    "\n",
    "    relevant_docs = 0\n",
    "\n",
    "    for value in relevance_results.items():\n",
    "        if value[1] == '1':\n",
    "            relevant_docs += 1\n",
    "\n",
    "    judgement_relevant_docs = 0\n",
    "    for value in judgement_results.items():\n",
    "        if value[1] == '1':\n",
    "            judgement_relevant_docs += 1\n",
    "    recall = judgement_relevant_docs / relevant_docs\n",
    "    precision = judgement_relevant_docs / len(judgement_results)\n",
    "    f_measure = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    ranked_relevant_docs = 0\n",
    "\n",
    "    for rank, doc in document_rankings.items():\n",
    "        print(judgement_results[doc])\n",
    "\n",
    "    # for value in document_rankings.items():\n",
    "    #     print(value)\n",
    "    # for rank, doc in document_rankings.items():\n",
    "    #     print(f'At position {rank}, docID: {doc}, precision = {precision}')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e193cfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2493': '1', '2494': '0', '3008': '1', '5004': '0', '5223': '0', '5225': '1', '5226': '1', '6635': '0', '7937': '0', '15744': '1', '17650': '0', '22961': '0', '25263': '0', '26711': '0', '27966': '0', '28198': '0', '31141': '1', '33961': '0', '38229': '0', '40239': '1', '40259': '0', '48148': '1', '48587': '0', '49633': '1', '50202': '0', '51493': '1', '52175': '0', '59813': '1', '62213': '0', '64966': '0', '65210': '1', '80118': '0', '80483': '0', '80484': '1', '80884': '0', '86042': '0', '86961': '1'}\n",
      "{'2493': '1', '2494': '0', '3008': '1', '5004': '0', '5223': '0', '5225': '1', '5226': '1', '6635': '0', '7937': '0', '15744': '1', '17650': '0', '22961': '0', '25263': '0', '26711': '0', '27966': '0', '28198': '0', '31141': '1', '33961': '0', '38229': '0', '40239': '1', '40259': '0', '48148': '1', '48587': '0', '49633': '1', '50202': '0', '51493': '1', '52175': '0', '59813': '1', '62213': '0', '64966': '0', '65210': '1', '80118': '0', '80483': '0', '80484': '1', '80884': '0', '86042': '0', '86961': '1'}\n",
      "{'2493': '1', '2494': '0', '3008': '1', '5004': '0', '5223': '0', '5225': '1', '5226': '1', '6635': '0', '7937': '0', '15744': '1', '17650': '0', '22961': '0', '25263': '0', '26711': '0', '27966': '0', '28198': '0', '31141': '1', '33961': '0', '38229': '0', '40239': '1', '40259': '0', '48148': '1', '48587': '0', '49633': '1', '50202': '0', '51493': '1', '52175': '0', '59813': '1', '62213': '0', '64966': '0', '65210': '1', '80118': '0', '80483': '0', '80484': '1', '80884': '0', '86042': '0', '86961': '1'}\n",
      "{'2493': '1', '2494': '0', '3008': '1', '5004': '0', '5223': '0', '5225': '1', '5226': '1', '6635': '0', '7937': '0', '15744': '1', '17650': '0', '22961': '0', '25263': '0', '26711': '0', '27966': '0', '28198': '0', '31141': '1', '33961': '0', '38229': '0', '40239': '1', '40259': '0', '48148': '1', '48587': '0', '49633': '1', '50202': '0', '51493': '1', '52175': '0', '59813': '1', '62213': '0', '64966': '0', '65210': '1', '80118': '0', '80483': '0', '80484': '1', '80884': '0', '86042': '0', '86961': '1'}\n",
      "{'2493': '1', '2494': '0', '3008': '1', '5004': '0', '5223': '0', '5225': '1', '5226': '1', '6635': '0', '7937': '0', '15744': '1', '17650': '0', '22961': '0', '25263': '0', '26711': '0', '27966': '0', '28198': '0', '31141': '1', '33961': '0', '38229': '0', '40239': '1', '40259': '0', '48148': '1', '48587': '0', '49633': '1', '50202': '0', '51493': '1', '52175': '0', '59813': '1', '62213': '0', '64966': '0', '65210': '1', '80118': '0', '80483': '0', '80484': '1', '80884': '0', '86042': '0', '86961': '1'}\n",
      "{'2493': '1', '2494': '0', '3008': '1', '5004': '0', '5223': '0', '5225': '1', '5226': '1', '6635': '0', '7937': '0', '15744': '1', '17650': '0', '22961': '0', '25263': '0', '26711': '0', '27966': '0', '28198': '0', '31141': '1', '33961': '0', '38229': '0', '40239': '1', '40259': '0', '48148': '1', '48587': '0', '49633': '1', '50202': '0', '51493': '1', '52175': '0', '59813': '1', '62213': '0', '64966': '0', '65210': '1', '80118': '0', '80483': '0', '80484': '1', '80884': '0', '86042': '0', '86961': '1'}\n",
      "{'2493': '1', '2494': '0', '3008': '1', '5004': '0', '5223': '0', '5225': '1', '5226': '1', '6635': '0', '7937': '0', '15744': '1', '17650': '0', '22961': '0', '25263': '0', '26711': '0', '27966': '0', '28198': '0', '31141': '1', '33961': '0', '38229': '0', '40239': '1', '40259': '0', '48148': '1', '48587': '0', '49633': '1', '50202': '0', '51493': '1', '52175': '0', '59813': '1', '62213': '0', '64966': '0', '65210': '1', '80118': '0', '80483': '0', '80484': '1', '80884': '0', '86042': '0', '86961': '1'}\n",
      "{'2493': '1', '2494': '0', '3008': '1', '5004': '0', '5223': '0', '5225': '1', '5226': '1', '6635': '0', '7937': '0', '15744': '1', '17650': '0', '22961': '0', '25263': '0', '26711': '0', '27966': '0', '28198': '0', '31141': '1', '33961': '0', '38229': '0', '40239': '1', '40259': '0', '48148': '1', '48587': '0', '49633': '1', '50202': '0', '51493': '1', '52175': '0', '59813': '1', '62213': '0', '64966': '0', '65210': '1', '80118': '0', '80483': '0', '80484': '1', '80884': '0', '86042': '0', '86961': '1'}\n",
      "{'2493': '1', '2494': '0', '3008': '1', '5004': '0', '5223': '0', '5225': '1', '5226': '1', '6635': '0', '7937': '0', '15744': '1', '17650': '0', '22961': '0', '25263': '0', '26711': '0', '27966': '0', '28198': '0', '31141': '1', '33961': '0', '38229': '0', '40239': '1', '40259': '0', '48148': '1', '48587': '0', '49633': '1', '50202': '0', '51493': '1', '52175': '0', '59813': '1', '62213': '0', '64966': '0', '65210': '1', '80118': '0', '80483': '0', '80484': '1', '80884': '0', '86042': '0', '86961': '1'}\n",
      "{'2493': '1', '2494': '0', '3008': '1', '5004': '0', '5223': '0', '5225': '1', '5226': '1', '6635': '0', '7937': '0', '15744': '1', '17650': '0', '22961': '0', '25263': '0', '26711': '0', '27966': '0', '28198': '0', '31141': '1', '33961': '0', '38229': '0', '40239': '1', '40259': '0', '48148': '1', '48587': '0', '49633': '1', '50202': '0', '51493': '1', '52175': '0', '59813': '1', '62213': '0', '64966': '0', '65210': '1', '80118': '0', '80483': '0', '80484': '1', '80884': '0', '86042': '0', '86961': '1'}\n"
     ]
    }
   ],
   "source": [
    "main_function_task3('rel_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83496a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ifn647_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IFN647 Week 6 Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop, you are going to design two language models by using inverted indexing structure. For a given query Q, a language model is going to find the relevant documents in a given folder, e.g., a folder “Test_Doc”. Assume the documents in the folder are indexed by the python function index_docs(), i.e., index_docs(“Test_Doc”, stop_words) which returns a dictionary with the following data structure: {term: {docID1: frequency1, DocID2: frequency2, …}, …}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "from stemming.porter2 import stem\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 \n",
    "\n",
    "Design function index_docs() to construct an inverted index, a dictionary\n",
    "{term:{docID1:freq1, DocID2:freq2, ...}, …}.\n",
    "\n",
    "For each document in the “Test_Doc” folder, it firstly finds the “docid” in tag <newsitem>. For each index term (excluding number, punctuations, and tags \\<p> and \\</p> in \\<text>), it also inserts\n",
    "the term into the index or accumulates its frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/aidanlockwood/Documents /GitHub/IFN647-Codebase/week6/wk6_data/Test_docs/'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 74\u001b[39m\n\u001b[32m     71\u001b[39m folder_name = \u001b[33m'\u001b[39m\u001b[33m/Users/aidanlockwood/Documents /GitHub/IFN647-Codebase/week6/wk6_data/Test_docs/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# Getting the list of the files in the test_docs folder\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m files = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m files.pop(\u001b[32m0\u001b[39m)\n\u001b[32m     77\u001b[39m \u001b[38;5;28mprint\u001b[39m(files)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/aidanlockwood/Documents /GitHub/IFN647-Codebase/week6/wk6_data/Test_docs/'"
     ]
    }
   ],
   "source": [
    "def index_docs(input_paths, stop_words):\n",
    "    word_count = 0\n",
    "    docid = ''\n",
    "    index = {}\n",
    "\n",
    "    for path in input_paths:               \n",
    "        my_file = open(f'/Users/aidanlockwood/Documents /GitHub/IFN647-Codebase/week6/wk6_data/Test_docs/{path}', 'r')\n",
    "\n",
    "        stopwords_file = open(stop_words, 'r')\n",
    "        stop_words_list = stopwords_file.readlines()\n",
    "        stopwords_file.close()\n",
    "\n",
    "        stop_words_list = stop_words_list[0].split(',')\n",
    "\n",
    "\n",
    "        start_end = False\n",
    "        parsed_text = []\n",
    "        \n",
    "\n",
    "        file_ = my_file.readlines()\n",
    "\n",
    "        for line in file_:\n",
    "            line = line.strip()\n",
    "\n",
    "            if line.startswith('<text>'):\n",
    "                start_end = True\n",
    "            if line.startswith('<newsitem '):\n",
    "                for part in line.split():\n",
    "                    if part.startswith('itemid='):\n",
    "                        docid = part.split('=')[1].split('/')[0]\n",
    "                        docid = docid.replace('\"', '')\n",
    "            elif line.startswith('<p>'):\n",
    "                line = line.replace('<p>', '').replace('</p>', '')\n",
    "                line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "                line = line.replace('quot', '')\n",
    "            elif line.startswith('</text>'):\n",
    "                start_end = False\n",
    "            if start_end:\n",
    "                parsed_text.append(line)\n",
    "        \n",
    "        split_text = []\n",
    "\n",
    "        for line in parsed_text:\n",
    "            for word in line.split(): \n",
    "                word_count += 1\n",
    "\n",
    "                if word.lower() not in stop_words_list and not word.isdigit():\n",
    "                    word = word.lower()\n",
    "                    split_text.append(stem(word))\n",
    "    \n",
    "        split_text.remove('<text>')\n",
    "\n",
    "        for word in split_text:\n",
    "            if word not in index:\n",
    "                word_count = 1\n",
    "            else:\n",
    "                if docid not in index[word]:\n",
    "                    index[word][docid] = 1\n",
    "                else:\n",
    "                    index[word][docid] += 1\n",
    "\n",
    "            if word not in index:\n",
    "                index[word] = {docid: word_count}\n",
    "            elif (word in index) and (docid not in index[word]):\n",
    "                index[word][docid] = word_count\n",
    "                \n",
    "        my_file.close()\n",
    "    return index\n",
    "\n",
    "# Testing the function on the Test_docs folder\n",
    "folder_name = '/Users/aidanlockwood/Documents /GitHub/IFN647-Codebase/week6/wk6_data/Test_docs/'\n",
    "\n",
    "# Getting the list of the files in the test_docs folder\n",
    "files = os.listdir(folder_name)\n",
    "files.pop(0)\n",
    "\n",
    "print(files)\n",
    "index_docs(files, 'wk6_data/common-english-words.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Let Q = {q1:1, q2:1, …, qn:1} be a dictionary, please define\n",
    "a function likelihood_IR(I, Q) to estimate P(Q|D), i.e., it returns\n",
    "the score of document D for the given query Q by using (insert function).\n",
    "\n",
    "where fqi,D is the number of times word qi occurs in document\n",
    "D, and |D| is the number of words in D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_IR(I, Q):\n",
    "    L = {}\n",
    "    R = {}\n",
    "\n",
    "    D_len = {}\n",
    "\n",
    "    for list in I.items():\n",
    "        for id in list[1].items():\n",
    "            R[id[0]] = 1\n",
    "            D_len[id[0]] = 0.5\n",
    "        if (list[0] in Q):\n",
    "            L[list[0]] = I[list[0]]\n",
    "    \n",
    "    for q_term in Q.items():\n",
    "        if not (q_term[0] in L):\n",
    "            L[q_term[0]] = {}\n",
    "    \n",
    "    for list in I.items():\n",
    "        for id in list[1].items():\n",
    "            D_len[id[0]] += D_len[id[0]] + id[1]\n",
    "    \n",
    "    for (d, sd) in R.items():\n",
    "\n",
    "        for (term, f) in L.items():\n",
    "            if not (d in f):\n",
    "                f[d] = 0\n",
    "            \n",
    "            sd = sd * (f[d] / D_len[d])\n",
    "\n",
    "        R[d] = sd\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'809481': 2.550546549747256e-19, '807600': 2.838968754325751e-51, '807606': 0.0, '809495': 0.0}\n"
     ]
    }
   ],
   "source": [
    "q2_terms = index_docs(files, 'wk6_data/common-english-words.txt')\n",
    "\n",
    "query = {'compani' : 1}\n",
    "\n",
    "IR_result = likelihood_IR(q2_terms, query)\n",
    "print(IR_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ifn647_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

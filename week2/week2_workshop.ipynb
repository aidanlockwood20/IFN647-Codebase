{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IFN647 Week 2 Workshop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Reading in an XML Document and Printing the Item ID and number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: \"6146\"\n",
      "Word count: 137\n"
     ]
    }
   ],
   "source": [
    "myfile = open('wk2_workshop_data/6146.xml', 'r')\n",
    "\n",
    "start_end = False\n",
    "\n",
    "file = myfile.readlines()\n",
    "word_count = 0\n",
    "news = ''\n",
    "\n",
    "for line in file:\n",
    "    line = line.strip()\n",
    "    if start_end == False:\n",
    "        if line.startswith('<newsitem '):\n",
    "            for part in line.split():\n",
    "                if part.startswith('itemid='):\n",
    "                    docid = part.split('=')[1].split('/')[0]\n",
    "                    break\n",
    "        if line.startswith('<text>'):\n",
    "            start_end = True\n",
    "    elif line.startswith('</text>'):\n",
    "        break\n",
    "    else: \n",
    "        line = line.replace('<p>', '').replace('</p>', '')\n",
    "        news = news + line + '\\n'\n",
    "        for term in line.split():\n",
    "            word_count += 1\n",
    "\n",
    "myfile.close()\n",
    "print('Document ID:', docid)\n",
    "print('Word count:', word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Designing a parsing function (parse_doc(input, stops)) to read a file and represent the file as a tuple\n",
    "    (word_count, {docid:curr_doc})\n",
    "\n",
    "Where:\n",
    "- word_count is the number of words in <text> to </text>\n",
    "- docid is simple assigned by the 'itemid' in <newsitem> \n",
    "- curr_doc is a dictionary of term_frequency pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the `select_sentence` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_doc(input_path, stop_words):\n",
    "    my_file = open(input_path, 'r')\n",
    "\n",
    "    stopwords_file = open(stop_words, 'r')\n",
    "    stop_words_list = stopwords_file.readlines()\n",
    "    stopwords_file.close()\n",
    "\n",
    "    stop_words_list = stop_words_list[0].split(',')\n",
    "\n",
    "    word_count = 0\n",
    "    docid = ''\n",
    "    curr_doc = {}\n",
    "\n",
    "    start_end = False\n",
    "    parsed_text = []\n",
    "    \n",
    "\n",
    "    file_ = my_file.readlines()\n",
    "\n",
    "    for line in file_:\n",
    "        line = line.strip()\n",
    "\n",
    "        if line.startswith('<text>'):\n",
    "            start_end = True\n",
    "        if line.startswith('<newsitem '):\n",
    "            for part in line.split():\n",
    "                if part.startswith('itemid='):\n",
    "                    docid = part.split('=')[1].split('/')[0]\n",
    "                    docid = docid.replace('\"', '')\n",
    "        elif line.startswith('<p>'):\n",
    "            line = line.replace('<p>', '').replace('</p>', '')\n",
    "            line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "            line = line.replace('quot', '')\n",
    "        elif line.startswith('</text>'):\n",
    "            start_end = False\n",
    "        if start_end:\n",
    "            parsed_text.append(line)\n",
    "\n",
    "    split_text = []\n",
    "\n",
    "    for line in parsed_text:\n",
    "        for word in line.split(): \n",
    "            word_count += 1\n",
    "\n",
    "            if word.lower() not in stop_words_list and not word.isdigit():\n",
    "                word = word.lower()\n",
    "                split_text.append(word)\n",
    "\n",
    "    split_text.remove('<text>')\n",
    "    for word in split_text:\n",
    "        if word not in curr_doc:\n",
    "            curr_doc[word] = 1\n",
    "        else:\n",
    "            curr_doc[word] += 1\n",
    "    \n",
    "    my_file.close()\n",
    "    return (word_count, docid, curr_doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening and initialising the stopwords variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_file = open('wk2_workshop_data/common-english-words.txt', 'r')\n",
    "stop_words_list = stopwords_file.readlines()\n",
    "stopwords_file.close()\n",
    "\n",
    "stop_words_list = stop_words_list[0].split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137, '6146', {'argentine': 1, 'bonds': 1, 'slightly': 1, 'higher': 1, 'small': 1, 'technical': 2, 'bounce': 2, 'wednesday': 1, 'amid': 1, 'low': 1, 'volume': 1, 'a': 1, 'trader': 2, 'large': 1, 'foreign': 1, 'bank': 1, 'slight': 1, 'opening': 1, 'expect': 1, 'prices': 1, 'change': 1, 'much': 1, 'during': 1, 'session': 1, 'marketmoving': 1, 'news': 1, 'expected': 2, 'the': 1, 'percent': 1, 'dollardenominated': 1, 'bocon': 1, 'previsional': 1, 'due': 2, 'rose': 2, 'argentinas': 2, 'frb': 1, 'there': 1, 'general': 1, 'uncertainty': 1, 'pointing': 1, 'events': 1, 'market': 1, 'waiting': 1, 'including': 1, 'passage': 1, 'governments': 1, 'new': 1, 'economic': 1, 'measures': 1, 'through': 1, 'congress': 1, 'now': 1, 'until': 1, 'early': 1, 'october': 1, 'in': 1, 'addition': 1, 'traders': 1, 'awaiting': 1, 'meeting': 1, 'friday': 1, 'between': 1, 'economy': 1, 'minister': 1, 'roque': 1, 'fernandez': 1, 'international': 1, 'monetary': 1, 'fund': 1, 'delegation': 1, 'fiscal': 1, 'deficit': 1, 'axel': 1, 'bugge': 1, 'buenos': 1, 'aires': 1, 'newsroom': 1})\n"
     ]
    }
   ],
   "source": [
    "text_to_parse = parse_doc('wk2_workshop_data/6146.xml', 'wk2_workshop_data/common-english-words.txt')\n",
    "\n",
    "print(text_to_parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: \n",
    "Design a main function to read a xml file and\n",
    "common-english-words.txt (the list of stopping words), call\n",
    "function parse_doc(input, stops), and print the itemid\n",
    "(docid), the number of words (word_count) and the number\n",
    "of terms (len(curr_doc))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_parsed_output(parsed_file, stopwords_file):\n",
    "    parsed_contents = parse_doc(parsed_file, stopwords_file)\n",
    "    word_count = parsed_contents[0]\n",
    "    docid = parsed_contents[1]\n",
    "    doc_freq = parsed_contents[2]\n",
    "\n",
    "    print(f'Document itemid: {docid} contains: {word_count} words and {len(doc_freq)} terms')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document itemid: 6146 contains: 137 words and 77 terms\n"
     ]
    }
   ],
   "source": [
    "display_parsed_output('wk2_workshop_data/6146.xml', 'wk2_workshop_data/common-english-words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

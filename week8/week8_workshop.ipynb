{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ff8430",
   "metadata": {},
   "source": [
    "# IFN647 Week 8 Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5422bc48",
   "metadata": {},
   "source": [
    "## Task 1: Ranking Documents using the Initial Query, Q\n",
    "Design a BM25 based IR model which uses query Q to rank documents in the \"Training_set\" folder and save the result into a text file; e.g., BaselineModel_R102.dat; where each row includes the document number and the corresponding BM25 score or ranking (descending order)\n",
    "\n",
    "Formally describe your ideac in an algorithm.\n",
    "\n",
    "P.S.: We believe everyone in the class should know how to do text pre-processing and calculate BM25 scores; therefore, we don't need to discuss the details of these parrts when you describe your ideas in an algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940aaca3",
   "metadata": {},
   "source": [
    "Algorithm RankDocs:\n",
    "\n",
    "Inputs: Q -> string query, U -> document set\n",
    "\n",
    "Outputs: a text file BaselineModel_R102.dat, where each row includes the document number and corresponding BM25/ranking score\n",
    "\n",
    "Step 1: Documents' representation \n",
    "- Let docs be an empty dictionary\n",
    "- For each xml document d in U:\n",
    "    - Get the document_ID\n",
    "    - Find the contents in \\<text>...\\</text>\n",
    "        - Get tokens (or terms) and their frequencies, and \n",
    "        - Append (document_id, {term:freq,...}) into docs\n",
    "Step 2: Calculate each term's document frequency and save the result into a dictionary df_\n",
    "Step 3: Use query Q, docs and df_ to work out the BM25 score for each document in U\n",
    "Step 4: Sort the documents based on their BM25 score and save the result into a file BaselineMode_R102.dat\n",
    "\n",
    "End Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9933f2e1",
   "metadata": {},
   "source": [
    "## Task 2: Training Data Generation\n",
    "Pseudo-Relevance Hypothesis: \"top-ranked documents (e.g. documents' BM25 scores greater than 1.00) are possibly relevant\".\n",
    "\n",
    "Design a python program to find a training set D which includes both D+ and D- in the given unlabelled document set U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b8fcd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = open('Ptraining_benchmark.txt', 'a')\n",
    "bm25_threshold = 1.00\n",
    "\n",
    "data_file = open('BaselineModel_R102.dat')\n",
    "file_ = data_file.readlines()\n",
    "\n",
    "for line in file_:\n",
    "    line = line.strip()\n",
    "    line_string = line.split()\n",
    "\n",
    "    if float(line_string[1]) > bm25_threshold:\n",
    "        output_file.write(f'R102 {line_string[0]} 1\\n')\n",
    "    \n",
    "    else:\n",
    "        output_file.write(f'R102 {line_string[0]} 0\\n')\n",
    "\n",
    "output_file.close()\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f62fbd",
   "metadata": {},
   "source": [
    "## Task 3: Discuss the precision and recall of the pseudo-relevance assumption\n",
    "Compare the relevance judgements (the true benchmark - \"Training_benchmark.txt\") and the pseudo one (\"PTraining_benchmark.txt\") and display the number of relevant documents, the number of retrieved documents, the recall, precisiom and F1 measure by using pseudo-relevance hypothesis, where we view documents in D+ as retrieved documents. You may use the function from week 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d43922",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ifn647_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

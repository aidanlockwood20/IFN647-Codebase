{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IFN647 Week 5 Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "from stemming.porter2 import stem\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 \n",
    "For the given two XML documents (you can download them from week 5 workshop and then save them in a folder, e.g. 'data'), design a python function **index_docs()** to index them (please remove stop words and index stems only). The returned index should be a dictionary {term: {docid1: freq1, docid2: freq2}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_docs(input_paths, stop_words):\n",
    "    word_count = 0\n",
    "    docid = ''\n",
    "    index = {}\n",
    "\n",
    "    for path in input_paths:               \n",
    "        my_file = open(path, 'r')\n",
    "\n",
    "        stopwords_file = open(stop_words, 'r')\n",
    "        stop_words_list = stopwords_file.readlines()\n",
    "        stopwords_file.close()\n",
    "\n",
    "        stop_words_list = stop_words_list[0].split(',')\n",
    "\n",
    "\n",
    "        start_end = False\n",
    "        parsed_text = []\n",
    "        \n",
    "\n",
    "        file_ = my_file.readlines()\n",
    "\n",
    "        for line in file_:\n",
    "            line = line.strip()\n",
    "\n",
    "            if line.startswith('<text>'):\n",
    "                start_end = True\n",
    "            if line.startswith('<newsitem '):\n",
    "                for part in line.split():\n",
    "                    if part.startswith('itemid='):\n",
    "                        docid = part.split('=')[1].split('/')[0]\n",
    "                        docid = docid.replace('\"', '')\n",
    "            elif line.startswith('<p>'):\n",
    "                line = line.replace('<p>', '').replace('</p>', '')\n",
    "                line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "                line = line.replace('quot', '')\n",
    "            elif line.startswith('</text>'):\n",
    "                start_end = False\n",
    "            if start_end:\n",
    "                parsed_text.append(line)\n",
    "        \n",
    "        split_text = []\n",
    "\n",
    "        for line in parsed_text:\n",
    "            for word in line.split(): \n",
    "                word_count += 1\n",
    "\n",
    "                if word.lower() not in stop_words_list and not word.isdigit():\n",
    "                    word = word.lower()\n",
    "                    split_text.append(stem(word))\n",
    "    \n",
    "        split_text.remove('<text>')\n",
    "\n",
    "        # print(split_text)\n",
    "        for word in split_text:\n",
    "            # word_count = 0\n",
    "            if word not in index:\n",
    "                word_count = 1\n",
    "            else:\n",
    "                word_count += 1\n",
    "\n",
    "            index[word] = {docid: word_count}\n",
    "        \n",
    "        # for word in split_text:\n",
    "        \n",
    "        my_file.close()\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = index_docs(['w5_data/data/6146.xml', 'w5_data/data/741299newsML.xml'], 'w5_data/common-english-words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'argentin': {'6146': 1},\n",
       " 'bond': {'6146': 1},\n",
       " 'slight': {'6146': 2},\n",
       " 'higher': {'6146': 1},\n",
       " 'small': {'6146': 1},\n",
       " 'technic': {'6146': 3},\n",
       " 'bounc': {'6146': 4},\n",
       " 'wednesday': {'6146': 1},\n",
       " 'amid': {'6146': 1},\n",
       " 'low': {'6146': 1},\n",
       " 'volum': {'6146': 1},\n",
       " 'trader': {'6146': 2},\n",
       " 'larg': {'6146': 1},\n",
       " 'foreign': {'6146': 1},\n",
       " 'bank': {'6146': 1},\n",
       " 'open': {'741299': 2},\n",
       " 'expect': {'6146': 2},\n",
       " 'price': {'6146': 1},\n",
       " 'chang': {'6146': 1},\n",
       " 'much': {'6146': 1},\n",
       " 'dure': {'741299': 8},\n",
       " 'session': {'6146': 1},\n",
       " 'marketmov': {'6146': 1},\n",
       " 'news': {'6146': 1},\n",
       " 'percent': {'6146': 1},\n",
       " 'dollardenomin': {'6146': 1},\n",
       " 'bocon': {'6146': 1},\n",
       " 'prevision': {'6146': 1},\n",
       " 'due': {'6146': 2},\n",
       " 'rose': {'6146': 3},\n",
       " 'argentina': {'6146': 2},\n",
       " 'frb': {'6146': 1},\n",
       " 'general': {'6146': 1},\n",
       " 'uncertainti': {'6146': 1},\n",
       " 'point': {'6146': 1},\n",
       " 'event': {'6146': 1},\n",
       " 'market': {'6146': 1},\n",
       " 'wait': {'6146': 1},\n",
       " 'includ': {'6146': 1},\n",
       " 'passag': {'6146': 1},\n",
       " 'govern': {'6146': 1},\n",
       " 'new': {'6146': 1},\n",
       " 'econom': {'6146': 1},\n",
       " 'measur': {'6146': 1},\n",
       " 'through': {'6146': 1},\n",
       " 'congress': {'6146': 1},\n",
       " 'now': {'6146': 1},\n",
       " 'until': {'6146': 1},\n",
       " 'earli': {'6146': 1},\n",
       " 'octob': {'6146': 1},\n",
       " 'addit': {'6146': 1},\n",
       " 'await': {'6146': 1},\n",
       " 'meet': {'6146': 1},\n",
       " 'friday': {'6146': 1},\n",
       " 'between': {'6146': 1},\n",
       " 'economi': {'6146': 1},\n",
       " 'minist': {'6146': 1},\n",
       " 'roqu': {'6146': 1},\n",
       " 'fernandez': {'6146': 1},\n",
       " 'intern': {'6146': 1},\n",
       " 'monetari': {'6146': 1},\n",
       " 'fund': {'6146': 1},\n",
       " 'deleg': {'6146': 1},\n",
       " 'fiscal': {'6146': 1},\n",
       " 'deficit': {'6146': 1},\n",
       " 'axel': {'6146': 1},\n",
       " 'bugg': {'6146': 1},\n",
       " 'bueno': {'6146': 1},\n",
       " 'air': {'6146': 1},\n",
       " 'newsroom': {'6146': 1},\n",
       " 'jj': {'741299': 1},\n",
       " 'lehto': {'741299': 2},\n",
       " 'finland': {'741299': 1},\n",
       " 'steve': {'741299': 1},\n",
       " 'soper': {'741299': 2},\n",
       " 'britain': {'741299': 1},\n",
       " 'drove': {'741299': 1},\n",
       " 'ail': {'741299': 1},\n",
       " 'mclaren': {'741299': 1},\n",
       " 'victori': {'741299': 2},\n",
       " 'fifth': {'741299': 1},\n",
       " 'round': {'741299': 1},\n",
       " 'world': {'741299': 1},\n",
       " 'gt': {'741299': 1},\n",
       " 'championship': {'741299': 1},\n",
       " 'sunday': {'741299': 1},\n",
       " 'beat': {'741299': 1},\n",
       " 'merced': {'741299': 1},\n",
       " 'german': {'741299': 2},\n",
       " 'bernd': {'741299': 1},\n",
       " 'schneider': {'741299': 2},\n",
       " 'austrian': {'741299': 1},\n",
       " 'alexand': {'741299': 1},\n",
       " 'wurz': {'741299': 1},\n",
       " 'second': {'741299': 7},\n",
       " 'enabl': {'741299': 1},\n",
       " 'up': {'741299': 3},\n",
       " '16point': {'741299': 1},\n",
       " 'lead': {'741299': 2},\n",
       " 'overal': {'741299': 1},\n",
       " 'stand': {'741299': 1},\n",
       " 'over': {'741299': 6},\n",
       " 'mount': {'741299': 1},\n",
       " 'strong': {'741299': 1},\n",
       " 'challeng': {'741299': 1},\n",
       " 'struggl': {'741299': 3},\n",
       " 'leader': {'741299': 1},\n",
       " 'final': {'741299': 1},\n",
       " 'minut': {'741299': 1},\n",
       " 'fourhour': {'741299': 1},\n",
       " 'race': {'741299': 1},\n",
       " 'car': {'741299': 2},\n",
       " 'handl': {'741299': 1},\n",
       " 'caus': {'741299': 1},\n",
       " 'broken': {'741299': 1},\n",
       " 'undertray': {'741299': 1},\n",
       " 'manag': {'741299': 1},\n",
       " 'hold': {'741299': 1},\n",
       " 'win': {'741299': 1},\n",
       " 'midrac': {'741299': 1},\n",
       " 'downpour': {'741299': 1},\n",
       " 'ardenn': {'741299': 1},\n",
       " 'mountain': {'741299': 1},\n",
       " 'thought': {'741299': 1},\n",
       " 'everyon': {'741299': 1},\n",
       " 'drive': {'741299': 1},\n",
       " 'dryweath': {'741299': 1},\n",
       " 'tyre': {'741299': 2},\n",
       " 'joke': {'741299': 1},\n",
       " 'afterward': {'741299': 1},\n",
       " 'swap': {'741299': 1},\n",
       " 'rain': {'741299': 1},\n",
       " 'exact': {'741299': 1},\n",
       " 'right': {'741299': 1},\n",
       " 'time': {'741299': 1},\n",
       " 'push': {'741299': 1},\n",
       " 'hard': {'741299': 1},\n",
       " 'big': {'741299': 1},\n",
       " 'third': {'741299': 1},\n",
       " 'finish': {'741299': 1},\n",
       " 'porsch': {'741299': 1},\n",
       " 'franc': {'741299': 1},\n",
       " 'bob': {'741299': 1},\n",
       " 'wollek': {'741299': 1},\n",
       " 'yannick': {'741299': 1},\n",
       " 'dalma': {'741299': 1},\n",
       " 'belgian': {'741299': 2},\n",
       " 'thierri': {'741299': 1},\n",
       " 'boutsen': {'741299': 1},\n",
       " 'former': {'741299': 1},\n",
       " 'formula': {'741299': 1},\n",
       " 'one': {'741299': 1},\n",
       " 'driver': {'741299': 1},\n",
       " 'switch': {'741299': 1},\n",
       " 'normal': {'741299': 1},\n",
       " 'share': {'741299': 1},\n",
       " 'han': {'741299': 1},\n",
       " 'stuck': {'741299': 1},\n",
       " 'follow': {'741299': 1},\n",
       " 'powerst': {'741299': 1},\n",
       " 'failur': {'741299': 1}}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "Design a python function **doc_at_a_time(I, Q)** where index I is a dictionary of term:dictionary of (itemid:freq), which returns a dictionary of docId:relevance for the given query Q (a term:freq dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_IR(I, Q):\n",
    "    L = {}\n",
    "    R = {}\n",
    "    D_len = {}\n",
    "\n",
    "    for list in I.items():\n",
    "        for id in list[1].items():\n",
    "            R[id[0]] = 1\n",
    "            D_len[id[0]] = 0.5\n",
    "\n",
    "            if list[0] in Q:\n",
    "                L[list[0]] = I[list[0]]\n",
    "    \n",
    "    for q_term in Q.items():\n",
    "        if not(q_term[0] in L):\n",
    "            L[q_term[0]] = {}\n",
    "    \n",
    "    for list in I.items():\n",
    "        for id in list[1].items():\n",
    "            D_len[id[0]] = D_len[id[0]] + id[1]\n",
    "\n",
    "    for (d, sd) in R.items():\n",
    "        for (term, f) in L.items():\n",
    "            if not (d in f):\n",
    "                f[d] = 0\n",
    "            sd = sd * (f[d] / D_len[d])\n",
    "        R[d] = sd\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_test = index_docs(['w5_data/data/741299newsML.xml'], 'w5_data/common-english-words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_at_a_time(I, Q):\n",
    "    IR_result = likelihood_IR(I, Q)\n",
    "    y = sorted(IR_result.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print('Likelihood Query Results -------------')\n",
    "    \n",
    "    for (id, w) in y: \n",
    "        print(f'Document ID: {id} and relevance weight: {w}') \n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood Query Results -------------\n",
      "Document ID: 6146 and relevance weight: 0.012422360248447204\n",
      "Document ID: 741299 and relevance weight: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('6146', 0.012422360248447204), ('741299', 0.0)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_test = index_docs(['w5_data/data/6146.xml', 'w5_data/data/741299newsML.xml'], 'w5_data/common-english-words.txt')\n",
    "doc_at_a_time(index_test, {'argentin': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "Design a python function **term_at_a_time(I, Q)**, where index I is a dictionary of a term:dictionary of (itemId:freq), which returns a dictionary of docId:relevance for the given query Q (a term:freq dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('belgian', {'741299': 2})]\n"
     ]
    }
   ],
   "source": [
    "def term_at_a_time(I, Q):\n",
    "    a = {}\n",
    "    l = []\n",
    "    r = []\n",
    "\n",
    "    k = 2\n",
    "    g = 1\n",
    "    f_score = 1\n",
    "\n",
    "    for term in Q.items():\n",
    "        if term[0] in I:\n",
    "            a[term[0]] = I[term[0]]\n",
    "    \n",
    "    for li in l:\n",
    "        try: \n",
    "            while True:\n",
    "                d, score = next(li)\n",
    "                a[d] += g * f_score\n",
    "        except StopIteration:\n",
    "            pass\n",
    "\n",
    "    for d, score in a.items():\n",
    "        r.append((d, score))\n",
    "        if len(r) > k:\n",
    "            r.pop((d, score))\n",
    "\n",
    "    return sorted(r, reverse = True)\n",
    "\n",
    "print(term_at_a_time(index_test, {'belgian': 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 \n",
    "Design a python main program to call the above three functions for a query, e/g/, Query = {'formula' : 1, 'one' : 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood Query Results -------------\n",
      "Document ID: 6146 and relevance weight: 0.012121212121212121\n",
      "Document at a Time Result [('6146', 0.012121212121212121)]\n",
      "Term at a Time Result []\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    index = index_docs(['w5_data/data/6146.xml', ], 'w5_data/common-english-words.txt')\n",
    "    doc_at_time = doc_at_a_time(index, {'argentin': 1})\n",
    "    term_at_time = term_at_a_time(index, {'belgian': 1})\n",
    "\n",
    "    print('Document at a Time Result', doc_at_time)\n",
    "    print('Term at a Time Result', term_at_time)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ifn647_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
